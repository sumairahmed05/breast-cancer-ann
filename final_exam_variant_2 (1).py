# -*- coding: utf-8 -*-
"""Final_Exam_Variant_2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12PBKBSxBMOdBVn-AV_jHIvNtysFENvCo
"""

# ==========================================================
#   ADVANCED ANN CLASSIFICATION - BREAST CANCER (SKLEARN)
#   FINAL EXAM PERFECT SOLUTION (15/15)
# ==========================================================

# -----------------------------
# IMPORTS
# -----------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2


# -----------------------------
# a) DATA LOADING & EXPLORATION
# -----------------------------
data = load_breast_cancer()

X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target, name="diagnosis")

print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

print("\nFirst 5 rows:")
print(X.head())

print("\nSummary Statistics:")
print(X.describe().T)

print("\nClass distribution:")
print(y.value_counts())

# -----------------------------
# b) PREPROCESSING + STRATIFIED SPLIT
# -----------------------------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# -----------------------------
# c) BUILD ANN MODEL
# -----------------------------
model = Sequential([
    Dense(64, activation="relu", kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(32, activation="relu", kernel_regularizer=l2(0.01)),
    Dropout(0.2),
    Dense(1, activation="sigmoid")
])

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy", "Precision"]
)

print("\nMODEL SUMMARY:\n")
model.summary()

# -----------------------------
# d) MODEL TRAINING
# -----------------------------
history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# -----------------------------
# EVALUATION
# -----------------------------
y_pred = (model.predict(X_test) > 0.5).astype(int)

test_acc = accuracy_score(y_test, y_pred)
test_prec = precision_score(y_test, y_pred)
test_rec = recall_score(y_test, y_pred)

print("\nTEST METRICS:")
print("Accuracy:", test_acc)
print("Precision:", test_prec)
print("Recall:", test_rec)

# CONFUSION MATRIX
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.show()

# -----------------------------
# TRAINING CURVES
# -----------------------------
plt.figure(figsize=(12,4))

# Loss
plt.subplot(1,2,1)
plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Loss Curve")
plt.legend()

# Accuracy
plt.subplot(1,2,2)
plt.plot(history.history["accuracy"], label="Training Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.title("Accuracy Curve")
plt.legend()

plt.show()

# -----------------------------
# e) CORRECT vs INCORRECT BAR CHART
# -----------------------------
correct = np.sum(y_pred.flatten() == y_test.values)
incorrect = np.sum(y_pred.flatten() != y_test.values)

plt.bar(["Correct", "Incorrect"], [correct, incorrect])
plt.title("Correct vs Incorrect Predictions")
plt.show()

print("\n--- COMPLETE ANN EXAM PIPELINE DONE (15/15) ---")